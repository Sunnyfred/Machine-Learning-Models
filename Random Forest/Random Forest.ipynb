{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math as m \n",
    "import collections\n",
    "import pandas as pd\n",
    "import sys \n",
    "import time\n",
    "\n",
    "\n",
    "def readin_csv_data(path):\n",
    "    df = pd.read_csv(path) \n",
    "    X = df.iloc[:,:-1].values \n",
    "    Y = df.iloc[:,-1].values \n",
    "    return X, Y\n",
    "\n",
    "def train_test_split(X, Y, train_size, shuffle):\n",
    "    ''' Perform tran/test datasets splitting '''\n",
    "    if shuffle:\n",
    "        randomize = np.arange(len(X))\n",
    "        np.random.shuffle(randomize)\n",
    "        X = X[randomize]\n",
    "        Y = Y[randomize]\n",
    "    s_id = int(len(Y) * train_size)\n",
    "    X_train, X_test = X[:s_id], X[s_id:]\n",
    "    Y_train, Y_test = Y[:s_id], Y[s_id:]\n",
    "\n",
    "    return X_train, X_test, Y_train, Y_test    \n",
    "\n",
    "\n",
    "\n",
    "def train_test_split_po(X, Y, train_size, shuffle):\n",
    "    ''' Perform tran/test datasets splitting '''\n",
    "    if shuffle:\n",
    "        randomize = np.arange(len(X))\n",
    "        np.random.shuffle(randomize)\n",
    "        X = X[randomize]\n",
    "        Y = Y[randomize]\n",
    "    s_id = int(len(Y) * train_size)\n",
    "    X_train, X_test = X[:s_id], X[s_id:]\n",
    "    Y_train, Y_test = Y[:s_id], Y[s_id:]\n",
    "    Y_train = Y_train.reshape((-1, 1))\n",
    "    X_train1 = np.append(X_train, Y_train, axis = 1) \n",
    "    X_train1 = X_train1[np.argsort(X_train1[:, 0])]\n",
    "    Y_test = Y_test.reshape((-1, 1))\n",
    "    X_test1 = np.append(X_test, Y_test, axis = 1) \n",
    "    X_test1 = X_test1[np.argsort(X_test1[:, 0])]\n",
    "    X_train, X_test = X_train1[:,:-1], X_test1[:,:-1]\n",
    "    Y_train, Y_test = X_train1[:,-1], X_test1[:,-1]\n",
    "    Y_train=np.squeeze(Y_train)\n",
    "    Y_test=np.squeeze(Y_test)\n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "def metric_accuracy(Y_label, Y_pred):\n",
    "    '''Evaluate the accuracy'''\n",
    "    correct_amount = 0 \n",
    "    for i in range(np.size(Y_pred)) :   #np.size: Number of elements in the array\n",
    "        if Y_label[i] == Y_pred[i] :             \n",
    "            correct_amount = correct_amount + 1\n",
    "    return correct_amount / np.size(Y_pred) * 100\n",
    "\n",
    "\n",
    "\n",
    "class RandomForestClassification():\n",
    "    '''Random Forest model for classification\n",
    "    ------------------------------------\n",
    "    Input data structure: numpy array with m x (d+1) shape, \n",
    "                          m rows of samples included, \n",
    "                          d columns of features/ttributes,\n",
    "                          and 1 column of target\n",
    "    criterion: gini, entropy or mse\n",
    "    max_depth: max depth for each tree\n",
    "    min_samples: min samples to stop splitting\n",
    "    max_features: the max numbers of features considered in decision tree\n",
    "    n_estimators: how many trees generated'''\n",
    "    \n",
    "    \n",
    "    def __init__(self, max_depth, min_samples, max_features, criterion, n_estimators):\n",
    "        self.md = max_depth\n",
    "        self.ms = min_samples\n",
    "        self.mf = max_features\n",
    "        self.depth_init = 1\n",
    "        self.criterion = criterion\n",
    "        self.ne = n_estimators\n",
    "    \n",
    "    def evaluate_information_entropy(self, p):\n",
    "        '''Evaluate information entropy component'''\n",
    "        if p==0:\n",
    "            return 0\n",
    "        elif p==1:\n",
    "            return 0\n",
    "        else:\n",
    "            return -p*np.log2(p)\n",
    "        \n",
    "    def evaluate_information_gain(self, left, right, classes):\n",
    "        '''Evaluate information gain'''\n",
    "        IG_after = 0\n",
    "        IG_before = 0\n",
    "        size_l = left.shape[0]\n",
    "        size_r = right.shape[0]\n",
    "        size_t = size_l +  size_r # Total sample No.\n",
    "        lr = np.vstack((left, right))\n",
    "        statis_lr = collections.Counter(lr[:,-1])\n",
    "        IG_before = sum([self.evaluate_information_entropy(float(statis_lr[class_i])/float(size_t)) for class_i in classes])\n",
    "        spaces = [left, right]\n",
    "        for space in spaces:\n",
    "            size = space.shape[0] # Sample No. in different group\n",
    "            if size == 0:   # Avoid 0 in denominator\n",
    "                continue     \n",
    "            tmp = 0.\n",
    "            statis = collections.Counter(space[:,-1])\n",
    "            tmp=sum([self.evaluate_information_entropy(float(statis[class_i])/float(size)) for class_i in classes])\n",
    "            IG_after += tmp * (size / size_t)\n",
    "        return IG_before - IG_after         \n",
    "       \n",
    "    def evaluate_gini_index(self, left, right, classes):\n",
    "        '''Gini impurity for classification'''\n",
    "        gini = 0\n",
    "        size_l = left.shape[0]\n",
    "        size_r = right.shape[0]\n",
    "        size_t = size_l +  size_r # Total sample No.\n",
    "        spaces = [left, right]\n",
    "        for space in spaces:\n",
    "            size = space.shape[0] # Sample No. in different group\n",
    "            if size == 0:   # Avoid 0 in denominator\n",
    "                continue     \n",
    "            tmp = 0.\n",
    "            statis = collections.Counter(space[:,-1])\n",
    "            tmp=sum([(float(statis[class_i])/float(size))**2.0 for class_i in classes])\n",
    "            gini += (1.0 - tmp) * (size / size_t)\n",
    "        return gini    \n",
    "    \n",
    "    def evaluate_mse_index(self, left, right):\n",
    "        '''MSE index for regression'''\n",
    "        mse = 0\n",
    "        spaces = [left, right]\n",
    "        for space in spaces:\n",
    "            mse += np.mean((space[:,-1] - np.mean(space[:,-1]))**2.)\n",
    "        return mse    \n",
    "    \n",
    "    def node(self, X):\n",
    "        '''split with the optimal gini, entropy, or mse index'''\n",
    "        classes = collections.Counter(X[:,-1])\n",
    "        classes = list(classes.keys())\n",
    "        tmp_value = 999     # This is a random choice, may need more careful for regession case.\n",
    "        tmp_IG = -999\n",
    "        tmp_gini = 999\n",
    "        # randomly select features, add randomness to system\n",
    "        column_id = sorted(np.random.choice(X.shape[1], self.mf, replace=True))\n",
    "        #column_id = sorted(np.random.choice(X.shape[1], X.shape[1], replace=False)) # Kill feature randomness\n",
    "        \n",
    "        for column in range(X[:,column_id].shape[1]-1):\n",
    "            for row in X:\n",
    "                left = np.empty((0, X.shape[1]))\n",
    "                right = np.empty((0, X.shape[1]))\n",
    "                for row2 in X:\n",
    "                    if row2[column] < row[column]:\n",
    "                        left = np.append(left, row2.reshape(-1, np.size(X, 1)), axis=0)\n",
    "                    else:\n",
    "                        right = np.append(right, row2.reshape(-1, np.size(X, 1)), axis=0)\n",
    "                if (self.criterion == 'gini'):\n",
    "                    gini = self.evaluate_gini_index(left, right, classes)\n",
    "                    if gini < tmp_gini:\n",
    "                            node_c, node_value, tmp_gini = column, row[column], gini\n",
    "                            left_branch, right_branch = left, right\n",
    "                elif (self.criterion == 'entropy'):\n",
    "                    IG = self.evaluate_information_gain(left, right, classes)\n",
    "                    if IG > tmp_IG:\n",
    "                            node_c, node_value, tmp_IG = column, row[column], IG\n",
    "                            left_branch, right_branch = left, right\n",
    "                elif (self.criterion == 'mse'):\n",
    "                    mse = self.evaluate_mse_index(left, right)\n",
    "                    if mse < tmp_value:\n",
    "                            node_c, node_value, tmp_value = column, row[column], mse\n",
    "                            left_branch, right_branch = left, right\n",
    "                else:\n",
    "                    print('I\\'m trying to add more criterion in it! ')\n",
    "        return {'feature_id': node_c, 'node_value': node_value, \\\n",
    "            'Left_branch': left_branch, 'Right_branch': right_branch}\n",
    "\n",
    "    def tree_grows(self, X, max_depth, min_samples, depth):\n",
    "        '''Recursively growing binary tree'''\n",
    "        left, right = X['Left_branch'], X['Right_branch']\n",
    "        for key in ['Left_branch', 'Right_branch']:\n",
    "            try:\n",
    "                del X[key]\n",
    "            except KeyError:\n",
    "                pass\n",
    "        #if np.size(left, 0)==0 or np.size(right, 0)==0:\n",
    "        if left.shape[0]==0 or right.shape[0]==0: # No need to split if encounter empty branch\n",
    "            X['Left_branch'] = self.leaf_node(np.vstack((left,right)))\n",
    "            X['Right_branch'] = self.leaf_node(np.vstack((left,right)))\n",
    "            return\n",
    "        if depth >= max_depth:   # tree depth should be smaller then max_depth\n",
    "            X['Left_branch'] = self.leaf_node(left)\n",
    "            X['Right_branch'] = self.leaf_node(right)\n",
    "            return\n",
    "        dict_tmp={'Left_branch':left, 'Right_branch':right}\n",
    "        for i in ['Left_branch', 'Right_branch']:   # Left/Right branches grow\n",
    "            #if np.size(dict_tmp[i], 0) > min_samples: \n",
    "            if dict_tmp[i].shape[0] > min_samples: \n",
    "                X[i] = self.node(dict_tmp[i])\n",
    "                self.tree_grows(X[i], self.md, self.ms, depth+1)\n",
    "            else:\n",
    "                X[i] = self.leaf_node(dict_tmp[i])\n",
    "                \n",
    "    def leaf_node(self, X):  \n",
    "        '''node is viewed as leaf, the most voted label is the leaf node label'''\n",
    "        if (self.criterion == 'gini' or 'entropy'):\n",
    "            statis = collections.Counter(X[:,-1])\n",
    "            max_votes=max(statis.values())\n",
    "            lst=[i for i in statis.keys() if statis[i]==max_votes] \n",
    "            return sorted(lst)[0]    \n",
    "        elif (self.criterion == 'mse'): \n",
    "            return np.mean(X[:,-1])  \n",
    "            \n",
    "    \n",
    "    def fit(self, X):\n",
    "        '''Used to obtain root node and build decision tree'''\n",
    "        #start1 = time.time()\n",
    "        Node = self.node(X) # generate node\n",
    "        #end1 = time.time()\n",
    "        #print(f\"Runtime of the node is {end1 - start1}\")\n",
    "        self.tree_grows(Node, self.md, self.ms, self.depth_init)\n",
    "        return Node\n",
    "    \n",
    "    def predict_sample(self, X, Y):\n",
    "        '''Used to predict each sample data Y based on tree X'''\n",
    "        if Y[int(X['feature_id'])] < X['node_value']:\n",
    "            if isinstance(X['Left_branch'], dict):\n",
    "                return self.predict_sample(X['Left_branch'], Y)\n",
    "            else:\n",
    "                y_pred = X['Left_branch']\n",
    "        else:\n",
    "            if isinstance(X['Right_branch'], dict):\n",
    "                return self.predict_sample(X['Right_branch'], Y)\n",
    "            else:\n",
    "                y_pred = X['Right_branch']\n",
    "        return y_pred     \n",
    "    \n",
    "    def make_prediction(self, X, Y):\n",
    "        '''make prediction for given test data Y\n",
    "           based on tree X'''\n",
    "        Y_pred = np.empty((0,1))\n",
    "        for i in range(Y.shape[0]):\n",
    "            tmp = self.predict_sample(X, Y[i])\n",
    "            tmp1 = np.array(tmp)\n",
    "            tmp1 = tmp1.reshape(-1,1)\n",
    "            Y_pred = np.append(Y_pred, tmp1, axis=0)\n",
    "        Y_pred = np.squeeze(Y_pred)\n",
    "        return Y_pred\n",
    "    \n",
    "    def export_tree(self, X, depth=0):\n",
    "        if isinstance(X, dict):\n",
    "            print(('%s%sfeature_%d <= %f')% (depth*'| ', '|--', X['feature_id'], X['node_value']))\n",
    "            self.export_tree(X['Left_branch'], depth+1)\n",
    "            print(('%s%sfeature_%d > %f')% (depth*'| ', '|--', X['feature_id'], X['node_value']))\n",
    "            self.export_tree(X['Right_branch'], depth+1)\n",
    "        else:\n",
    "            if self.criterion == 'gini' or 'entropy':\n",
    "                print(('%s%sclass: %f')%(depth*'| ', '|--', X))\n",
    "            elif self.criterion == 'mse':\n",
    "                print(('%s%savg value: %f')%(depth*'| ', '|--', X))\n",
    "            \n",
    "    def bootstrapping(self, X):\n",
    "        '''Leave-one-out cross validation to perform out-of-bag(oob) estimation,\n",
    "           the oob prob. is (1-1/m)^m, if m->inf, prob. -> e^-1 ~ 0.36787.\n",
    "           The bootstrapping is the process of sampling m points with replacement,\n",
    "           this add randomness to each decision tree.'''\n",
    "        b_id = sorted(np.random.choice(X.shape[0], X.shape[0], replace=True))\n",
    "        X_b = X[b_id, :]\n",
    "        oob_id = [i for i in range(X.shape[0]) if i not in b_id]\n",
    "        X_oob = X[oob_id, :]\n",
    "        return X_b, X_oob\n",
    "            \n",
    "    def oob_accuracy(self, X, Y):\n",
    "        '''evaluate accuracy for Y\n",
    "           based on tree X'''\n",
    "        y_pred_oob = np.zeros(Y.shape[0])\n",
    "        y_pred_oob = self.make_prediction(X, Y)\n",
    "        y_label_oob = Y[:, -1].astype(int)\n",
    "        return metric_accuracy(y_label_oob, y_pred_oob.astype(int))\n",
    "\n",
    "        \n",
    "    def forest_fit(self, X):\n",
    "        random_forest = []\n",
    "        for i in range(self.ne):\n",
    "            X_b, X_oob = self.bootstrapping(X)\n",
    "            single_tree = self.fit(X_b)\n",
    "            print('OOB accuracy for single tree_', i+1, ': ', self.oob_accuracy(single_tree, X_oob), '%')\n",
    "            random_forest.append(single_tree)\n",
    "        return random_forest\n",
    "  \n",
    "    def make_prediction_rf(self, X, Y):\n",
    "        '''make prediction for given test data Y\n",
    "           based on random forest(rf) X'''\n",
    "        Y_pred = np.empty((0,1))\n",
    "        for i in range(Y.shape[0]):\n",
    "            tmp_l = []\n",
    "            tmp_l = [self.predict_sample(tree, Y[i]) for tree in X]\n",
    "            tmp = max(tmp_l, key = tmp_l.count)\n",
    "            tmp1 = np.array(tmp)\n",
    "            tmp1 = tmp1.reshape(-1,1)\n",
    "            Y_pred = np.append(Y_pred, tmp1, axis=0)\n",
    "        Y_pred = np.squeeze(Y_pred)\n",
    "        return Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB accuracy for single tree_ 1 :  89.23076923076924 %\n",
      "OOB accuracy for single tree_ 2 :  89.6103896103896 %\n",
      "OOB accuracy for single tree_ 3 :  78.57142857142857 %\n",
      "OOB accuracy for single tree_ 4 :  89.02439024390245 %\n",
      "OOB accuracy for single tree_ 5 :  85.9375 %\n",
      "OOB accuracy for single tree_ 6 :  86.8421052631579 %\n",
      "OOB accuracy for single tree_ 7 :  93.15068493150685 %\n",
      "OOB accuracy for single tree_ 8 :  88.73239436619718 %\n",
      "OOB accuracy for single tree_ 9 :  93.33333333333333 %\n",
      "OOB accuracy for single tree_ 10 :  90.27777777777779 %\n",
      "OOB accuracy for single tree_ 11 :  94.73684210526315 %\n",
      "OOB accuracy for single tree_ 12 :  85.13513513513513 %\n",
      "OOB accuracy for single tree_ 13 :  85.71428571428571 %\n",
      "OOB accuracy for single tree_ 14 :  86.07594936708861 %\n",
      "OOB accuracy for single tree_ 15 :  91.42857142857143 %\n",
      "OOB accuracy for single tree_ 16 :  91.78082191780823 %\n",
      "OOB accuracy for single tree_ 17 :  80.76923076923077 %\n",
      "OOB accuracy for single tree_ 18 :  87.01298701298701 %\n",
      "OOB accuracy for single tree_ 19 :  91.66666666666666 %\n",
      "OOB accuracy for single tree_ 20 :  88.1578947368421 %\n",
      "Random Forest Accuracy:  95.0  %\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "\n",
    "    truncate_train=200\n",
    "    truncate_test=20\n",
    "    X, Y = readin_csv_data('data_banknote_authentication.csv')\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=.9, shuffle=True)\n",
    "    X_trainset = np.hstack((X_train[:truncate_train, :], Y_train.reshape(-1,1)[:truncate_train, :]))\n",
    "    X_testset = np.hstack((X_test[:truncate_test, :], Y_test.reshape(-1,1)[:truncate_test, :]))\n",
    "    model =  RandomForestClassification(n_estimators=20, max_features=4, max_depth = 3, min_samples = 10, criterion='gini')   \n",
    "    tree = model.forest_fit(X_trainset)\n",
    "    #print(tree)\n",
    "    #model.export_tree(tree)\n",
    "    y_pred = np.zeros(X_testset.shape[0])\n",
    "    y_pred = model.make_prediction_rf(tree, X_testset)\n",
    "    y_label = X_testset[:, -1].astype(int)\n",
    "    print('Random Forest Accuracy: ', metric_accuracy(y_label, y_pred.astype(int)), ' %') \n",
    "    #g = Digraph('G', filename='test.gv')\n",
    "    #visualize_tree_root_node(g, tree)\n",
    "    #visualize_tree(g, tree)\n",
    "    #print(g)\n",
    "\n",
    "if __name__ == '__main__':  \n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
